{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook used to obtain daily stock data information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs to webscrape companies of target\n",
    "midcap = \"http://investsnips.com/list-of-publicly-traded-mid-cap-oil-gas-exploration-and-production-companies/\"\n",
    "largecap = \"http://investsnips.com/list-of-publicly-traded-large-cap-oil-gas-exploration-and-production-companies/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape for midcap companies\n",
    "def midcap_ls(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    midcap_html = soup.find(class_=\"et_pb_text_inner\").find_all('a')\n",
    "    company_list = []\n",
    "    for text in midcap_html:\n",
    "        company = text.get_text()\n",
    "        if re.findall(\"Mid-Cap+\", company):\n",
    "            company_list = []        \n",
    "            continue        \n",
    "        company_list.append(company)    \n",
    "        if re.findall(\"WPX+\", company):\n",
    "            break\n",
    "    return company_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape for largecap companies\n",
    "def largecap_ls(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    largecap_html = soup.find(class_=\"et_pb_text_inner\").find_all('a')\n",
    "    company_list = []\n",
    "    for text in largecap_html:\n",
    "        company = text.get_text()\n",
    "        if re.findall(\"Oil and+\", company):\n",
    "            company_list = []        \n",
    "            continue        \n",
    "        company_list.append(company)    \n",
    "        if re.findall(\"Pioneer+\", company):\n",
    "            break\n",
    "    return company_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full list of all the companies\n",
    "all_companies = midcap_ls(midcap) + (largecap_ls(largecap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Antero Resources Corporation (AR)',\n",
       " 'Callon Petroleum Company (CPE)',\n",
       " 'Centennial Resource Development, Inc. (CDEV)',\n",
       " 'Chesapeake Energy Corporation (CHK)',\n",
       " 'Diamondback Energy, Inc. (FANG)',\n",
       " 'Energen Corporation (EGN)',\n",
       " 'EQT Corporation (EQT)',\n",
       " 'Extraction Oil & Gas, Inc. (XOG)',\n",
       " 'Gulfport Energy Corporation (GPOR)',\n",
       " 'Jagged Peak Energy Inc. (JAG)',\n",
       " 'Laredo Petroleum, Inc. (LPI)',\n",
       " 'Matador Resources Company (MTDR)',\n",
       " 'MDU Resources Group, Inc. (MDU)',\n",
       " 'Murphy Oil Corporation (MUR)',\n",
       " 'Newfield Exploration Company (NFX)',\n",
       " 'Oasis Petroleum Inc. (OAS)',\n",
       " 'Parsley Energy, Inc. (PE)',\n",
       " 'PDC Energy, Inc. (PDCE)',\n",
       " 'Range Resources Corporation (RRC)',\n",
       " 'Rice Energy Inc. (RICE)',\n",
       " 'RSP Permian, Inc. (RSPP)',\n",
       " 'SM Energy Company (SM)',\n",
       " 'Southwestern Energy Company (SWN)',\n",
       " 'Whiting Petroleum Corporation (WLL)',\n",
       " 'WPX Energy, Inc. (WPX)',\n",
       " 'Anadarko Petroleum Corporation (APC)',\n",
       " 'Apache Corporation (APA)',\n",
       " 'Cabot Oil & Gas Corporation (COG)',\n",
       " 'Canadian Natural Resources Limited (CNQ)',\n",
       " 'Cimarex Energy Co. (XEC)',\n",
       " 'CNOOC Limited (CEO)',\n",
       " 'Concho Resources Inc. (CXO)',\n",
       " 'ConocoPhillips (COP)',\n",
       " 'Continental Resources, Inc. (CLR)',\n",
       " 'Devon Energy Corporation (DVN)',\n",
       " 'Encana Corporation (ECA)',\n",
       " 'EOG Resources, Inc. (EOG)',\n",
       " 'Hess Corporation (HES)',\n",
       " 'Marathon Oil Corporation (MRO)',\n",
       " 'Noble Energy Inc. (NBL)',\n",
       " 'Occidental Petroleum Corporation (OXY)',\n",
       " 'Pioneer Natural Resources Company (PXD)']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pull just stock ticker names\n",
    "def ticker_name(company_list):\n",
    "    ticker_ls = []\n",
    "    for company in company_list:\n",
    "        start = company.find(\"(\") + 1\n",
    "        end = company.find(\")\")\n",
    "        ticker_ls.append(company[start:end])\n",
    "    return ticker_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full list of comapny's stock ticker \n",
    "ticker_list = ticker_name(all_companies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependecies\n",
    "import pandas as pd\n",
    "import time\n",
    "import quandl\n",
    "quandl.ApiConfig.api_key = \"VDT3_1W-5_X47sL4YjsC\"\n",
    "quandl.ApiConfig.verify_ssl = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicho\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "# Crude prices for each day\n",
    "crude_price = quandl.get('EIA/PET_RWTC_D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "crude_price_df = crude_price.reset_index()\n",
    "crude_price_df.to_csv(\"../data/crudePrice.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only run once\n",
    "## If no files in data folder run\n",
    "### Only needed to create csv files for each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "staging\n",
      "good to go\n",
      "staging\n",
      "good to go\n",
      "staging\n",
      "good to go\n",
      "staging\n",
      "good to go\n",
      "staging\n",
      "good to go\n",
      "staging\n",
      "Error for EGN\n",
      "staging\n",
      "good to go\n",
      "staging\n",
      "good to go\n",
      "staging\n",
      "good to go\n",
      "staging\n",
      "good to go\n",
      "staging\n",
      "good to go\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Time Series (Daily)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d1986d61fad4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"good to go\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;31m# Formats data into dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mticker_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker_json\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Time Series (Daily)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m                                 \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                                 \u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Time Series (Daily)'"
     ]
    }
   ],
   "source": [
    "# Url to be used to access ticker api data \n",
    "url = \"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol={}&outputsize=full&apikey=BGZ66XLUGR27TO4M\"\n",
    "path = \"../data/\"\n",
    "counter = 1\n",
    "\n",
    "# loop to create csv for each Company\n",
    "for tick in ticker_list:\n",
    "    # Will add company of interest to the API and make the request\n",
    "    url_ticker = url.format(tick)\n",
    "    response = requests.get(url_ticker)\n",
    "    # Makes sure that request suceeded\n",
    "    if response.status_code == 200:\n",
    "        print(\"staging\")\n",
    "        ticker_json = response.json()\n",
    "        # Checks to make sure the API returned actual information\n",
    "        if next(iter(ticker_json)) == \"Error Message\":\n",
    "            print(\"Error for \" + tick)\n",
    "            pass\n",
    "        else:\n",
    "            print(\"good to go\")\n",
    "            # Formats data into dataframe\n",
    "            ticker_df = pd.DataFrame(ticker_json['Time Series (Daily)']).\\\n",
    "                                transpose().\\\n",
    "                                reset_index().\\\n",
    "                                rename(columns={\"index\":\"date\", \"1. open\":\"open\", \"2. high\":\"high\", \"3. low\":\"low\",\n",
    "                                                \"4. close\": \"close\", \"5. adjusted close\":\"adjusted_close\",\n",
    "                                                \"6. volume\":\"volume\", \"7. dividend amount\": \"dividend_amount\", \n",
    "                                                \"8. split coefficient\":\"split_coefficient\"})\n",
    "            full_path = path + tick +\".csv\"\n",
    "            # Saves file as csv\n",
    "            ticker_df.to_csv(full_path)\n",
    "            # Counter used to keep track of number of processed items\n",
    "            counter+=1\n",
    "            # Conditional to make the process wait to prevent too many allowed request in a minute\n",
    "            if counter%5 == 1:\n",
    "                time.sleep(70) # seconds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
